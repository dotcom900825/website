							<table class="table">
								<tbody>
									<tr>
										<th id="guiding" valign="top">Category</th>
										<th id="unsatisfactory" valign="top">Nope</th>
										<th id="minimum" valign="top">Weak</th>
										<th id="satisfactory" valign="top">Proficient</th>
										<th id="above" valign="top">Mastery</th>
									</tr>
									<tr>
										<td>Relation to Nielsen’s Heuristics<br /><span style="color:lightGray;">3 points</span></td>
										<td>Minimal relation to Nielsen’s heuristics.</td>
										<td>Analysis and relations to Nielsen's heuristics are overly vague or tough to understand.</td>
										<td>Evaluation applies heuristics to partner's prototype in a useful, organized way--most of the time. There may be a few parts, though, that don't seem as related to the heuristics, which may make the reader wonder if the evaluator was still familiarizing himself with the heuristics during the evaluation.</td>
										<td>Clearly grounded in Nielsen's heuristics. This evaluation could be used in the lecture about Nielsen's heuristics.</td>
									</tr>
									<tr>
										<td>Volume of Feedback<br /><span style="color:lightGray;">3 points</span></td>
										<td>No interpretable, individually-generated feedback. Could be empty, illegible, copied from other group members, or all generated as a group (rather than indivudally).</td>
										<td>A small amount of legible, individually-generated feedback. The evaluator missed a majority of the obvious heuristic violations in the prototype.</td>
										<td>There is a good amount of feedback, but there probably could be more. A reader gets the feeling that the evaluator was trying to be "nice" or "hold back" certain feedback.</td>
										<td>At least 15 violations found, employing at least 8 of the 10 heuristics. You really couldn't ask for more. Clearly the evaluator "showed no mercy."</td>
									</tr>
									<tr>
										<td>Quality of Feedback<br /><span style="color:lightGray;">3 points</span></td>
										<td>No feedback given.</td>
										<td>Most of the feedback was obvious (you could have come up with it without really going through the HE process) or vague (the designers might not be sure what the problem you're referring to is).</td>
										<td>There is a good amount of high-quality feedback, but some feedback may still be obvious or vague. It also may lack a useful comparison between the two prototypes.</td>
										<td>Insightful, widely varied feedback that compared the two prototypes. This feedback will give the designers a solid grasp of the advantages and drawbacks of each design, and help them decide which design or which features to implement.</td>
									</tr>
									<tr>
										<td>Severity Ratings<br /><span style="color:lightGray;">2 points</span></td>
										<td>At least half of the problems have no ratings.</td>
										<td colspan=2>A large fraction of the problems have poorly-chosen severity ratings. A severity rating is poorly chosen when serious problems--such as fundamental issues with the core information architecture--are rated low-severity, or if minor issues--like small layout issues--are rated high severity.</td>
										<td>Pretty much all of the problems have appropriate severity ratings. As a result, the group that made the prototypes can make a good prioritized list of problems to address in their designs.</td>
									</tr>
									<tr>
										<td>Aggregate Evaluation &&nbsp;Reflection<br /><span style="color:lightGray;">3 pts</span></td>
										<td>None submitted online.</td>
										<td>The conclusions reached by the evaluators as a group was just a rehash of all the individual evaluations. No potential solutions to major usability problems were brainstormed.</td>
										<td>The conclusions reached by the evaluators as a group was just a rehash of all the individual evaluations. Potential solutions to major usability problems were brainstormed, but they were obvious, and something that the group that made the prototypes could have figured out for themselves.</td>
										<td>The conclusions reached by the evaluators as a group were more insightful than the aggregation of all the individual evaluations. Potential solutions to major usability problems were creative and insightful.</td>
									</tr>
									<tr>
										<td>Home Screen<br /><span style="color:lightGray;">3 pts</span></td>
										<td>No link to an HTML home screen provided. Image-based mock-ups (e.g.,&nbsp;Photoshop) receive no credit.</td>
										<td>HTML home screen has little content. </td>
										<td>HTML home screen appears to have most of its content. It does not need to be pretty or highly stylized. </td>
										<td>Home screen content is very thoroughly developed. It does not need to be pretty or highly stylized.</td>
									</tr>
									<tr>
										<td headers="guiding" colspan=2><br>Outside the Box<br><span style="color:lightGray;"><span style="color:lightGray;">1 pt</td>
										<td colspan=3 align=right>Multiple parts of the feedback were innovative and interesting. The student has obviously spent a lot of time and energy applying Nielsen's Heuristics in a clever manner.</td>
									</tr>
								</tbody>
							</table>